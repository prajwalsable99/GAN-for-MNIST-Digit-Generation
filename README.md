# GAN-for-MNIST-Digit-Generation

![image](https://github.com/user-attachments/assets/be63e5b1-2ff1-4a22-a6fc-409b02389f1f)

This repository contains an implementation of a **Generative Adversarial Network (GAN)** using PyTorch. The model is trained on the **MNIST dataset** (handwritten digits) and generates synthetic images based on random noise.

## Table of Contents

- [Overview](#overview)
- [Requirements](#requirements)
- [Model Architecture](#model-architecture)
- [License](#license)

## Overview

The project implements a simple GAN architecture with the following components:

1. **Generator**: A neural network that generates fake images from random noise.
2. **Discriminator**: A neural network that classifies images as real (from the MNIST dataset) or fake (generated by the generator).

The network is trained using the **MNIST dataset**, a collection of 28x28 grayscale images of handwritten digits, and aims to generate similar images.

## Requirements

- Python 3.x
- PyTorch 1.x or higher
- torchvision
- tqdm
- matplotlib

## Model Architecture

```
- Generator
The Generator consists of several layers that progressively transform the latent vector into a generated image:

Input: Latent vector z (size 64).
Layers: Four fully connected layers followed by Batch Normalization and ReLU.
Output: Image of size 784 (flattened 28x28) with values between 0 and 1 (Sigmoid activation).

- Discriminator
The Discriminator classifies an input image as real or fake:

Input: Image of size 784 (flattened 28x28).
Layers: Three fully connected layers with LeakyReLU.
Output: Single value (real or fake) from a sigmoid output layer.

-Summary

Generator: Transforms random noise into a synthetic image.
Discriminator: Classifies an image as real or fake.
Loss: Binary Cross-Entropy for both networks.
The Generator and Discriminator are trained together through adversarial learning, where the Generator improves at creating realistic images, and the Discriminator improves at distinguishing real from fake.
```


## License
This project is licensed under the MIT License - see the LICENSE file for details.
